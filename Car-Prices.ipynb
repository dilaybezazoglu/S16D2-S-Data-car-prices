{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Araba FiyatlarÄ± (Car Prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¯ Bu challengeâ€™Ä±n amacÄ±, bir dataset hazÄ±rlamak ve ÅŸimdiye kadar Ã¶ÄŸrendiÄŸiniz bazÄ± feature selection tekniklerini uygulamaktÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸš— Arabalarla ilgili bir veri setiyle Ã§alÄ±ÅŸÄ±yoruz ve bir arabanÄ±n pahalÄ± mÄ± yoksa ucuz mu olduÄŸunu tahmin etmek istiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# SayÄ±sal bir Ã¶zelliÄŸin normal daÄŸÄ±lÄ±m gÃ¶sterip gÃ¶stermediÄŸini kontrol etme\n",
    "from statsmodels.graphics.gofplots import qqplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://d32aokrjazspmn.cloudfront.net/materials/ML_Cars_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspiration</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginetype</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>stroke</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.1</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>2.68</td>\n",
       "      <td>5000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>64.1</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>2.68</td>\n",
       "      <td>5000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2823</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>six</td>\n",
       "      <td>3.47</td>\n",
       "      <td>5000</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2337</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>3.40</td>\n",
       "      <td>5500</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>std</td>\n",
       "      <td>front</td>\n",
       "      <td>66.4</td>\n",
       "      <td>2824</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>3.40</td>\n",
       "      <td>5500</td>\n",
       "      <td>expensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aspiration enginelocation carwidth  curbweight enginetype cylindernumber  \\\n",
       "0        std          front     64.1        2548       dohc           four   \n",
       "1        std          front     64.1        2548       dohc           four   \n",
       "2        std          front     65.5        2823       ohcv            six   \n",
       "3        std          front      NaN        2337        ohc           four   \n",
       "4        std          front     66.4        2824        ohc           five   \n",
       "\n",
       "   stroke  peakrpm      price  \n",
       "0    2.68     5000  expensive  \n",
       "1    2.68     5000  expensive  \n",
       "2    3.47     5000  expensive  \n",
       "3    3.40     5500  expensive  \n",
       "4    3.40     5500  expensive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ CSV dosyasÄ±nÄ± `df` adlÄ± bir veri Ã§erÃ§evesine yÃ¼kleyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â„¹ï¸ Datasetâ€™in aÃ§Ä±klamasÄ± [burada](https://drive.google.com/file/d/1ADSyjWfRGYqdXwCCN4PPC7PjQeMZ-ap-/view?usp=sharing ) mevcuttur. Egzersiz boyunca buna mutlaka referans verin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Yinelenenler (Duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Varsa, veri kÃ¼mesinden yinelenenleri kaldÄ±rÄ±n. â“\n",
    "\n",
    "*Veri Ã§erÃ§evesini `df`* Ã¼zerine yazÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# SENÄ°N KODUN BURAYA\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2)  Eksik deÄŸerler (Missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Eksik deÄŸerleri bulun ve bunlarÄ± ya `strategy = \"most frequent\"` (kategorik deÄŸiÅŸkenler iÃ§in) ya da `strategy = \"median\"` (sayÄ±sal deÄŸiÅŸkenler iÃ§in) kullanarak doldurun â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "imputer_num = SimpleImputer(strategy=\"median\")\n",
    "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `carwidth`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>carwidth</code> sÃ¼tununda eksik deÄŸerler birden fazla ÅŸekilde temsil edilmektedir. BazÄ±larÄ± <code>np.nan</code>, bazÄ±larÄ± ise <code>*</code> olarak yer alÄ±r. Bunlar tespit edildikten sonra, eksik deÄŸerler verinin %30â€™undan daha azÄ±nÄ± oluÅŸturduÄŸu iÃ§in medyan deÄŸerle doldurulabilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df[[\"carwidth\"]] = imputer.fit_transform(df[[\"carwidth\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>enginelocation</code> kategorik bir feature olduÄŸundan ve kategorilerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu <code>front</code> olduÄŸu iÃ§in, en sÄ±k gÃ¶rÃ¼len deÄŸerle doldurun.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aspiration', 'enginelocation', 'carwidth', 'curbweight', 'enginetype',\n",
       "       'cylindernumber', 'stroke', 'peakrpm', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "df[[\"enginelocation\"]] = imputer.fit_transform(df[[\"enginelocation\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/dilay/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/dilay/Desktop/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_missing_values.py::TestMissing_values::test_carwidth \u001b[32mPASSED\u001b[0m\u001b[32m         [ 50%]\u001b[0m\n",
      "test_missing_values.py::TestMissing_values::test_engine_location \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.37s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/missing_values.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed missing_values step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) SayÄ±sal Ã¶zelliklerin Ã¶lÃ§eklendirilmesi (Scaling the numerical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 191 entries, 0 to 204\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   aspiration      191 non-null    object \n",
      " 1   enginelocation  191 non-null    object \n",
      " 2   carwidth        191 non-null    object \n",
      " 3   curbweight      191 non-null    float64\n",
      " 4   enginetype      191 non-null    object \n",
      " 5   cylindernumber  191 non-null    object \n",
      " 6   stroke          191 non-null    float64\n",
      " 7   peakrpm         191 non-null    float64\n",
      " 8   price           191 non-null    object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 14.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# HatÄ±rlatma olarak, DataFrame hakkÄ±nda bazÄ± bilgiler\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['curbweight', 'stroke', 'peakrpm'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ve iÅŸte Ã¶lÃ§eklendirmemiz gereken veri kÃ¼mesinin sayÄ±sal Ã¶zellikleri\n",
    "numerical_features = df.select_dtypes(exclude=['object']).columns\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: SayÄ±sal featureâ€™larÄ±n Ã¶lÃ§eklenmesi** â“\n",
    "\n",
    "SayÄ±sal featureâ€™larÄ± aykÄ±rÄ± deÄŸerler (outliers) ve daÄŸÄ±lÄ±mlarÄ± aÃ§Ä±sÄ±ndan inceleyin ve duruma gÃ¶re aÅŸaÄŸÄ±daki yÃ¶ntemleri uygulayÄ±n:\n",
    "- Robust Scaler\n",
    "- Standard Scaler\n",
    "\n",
    "DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ deÄŸerlerle orijinal sÃ¼tunlarÄ± deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `peakrpm` , `carwidth` , & `stroke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "\n",
    "    \n",
    "â„¹ï¸ <code>peakrpm</code>, <code>carwidth</code> ve <code>stroke</code> normal daÄŸÄ±lÄ±ma sahiptir ancak aynÄ± zamanda bazÄ± aykÄ±rÄ± deÄŸerler (outlier) iÃ§erir. Bu nedenle `RobustScaler()` kullanÄ±lmasÄ± tavsiye edilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler_peakrpm = RobustScaler()\n",
    "df[[\"peakrpm\"]] = scaler_peakrpm.fit_transform(df[[\"peakrpm\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df[\"carwidth\"] = pd.to_numeric(df[\"carwidth\"], errors=\"coerce\")\n",
    "\n",
    "imputer_carwidth = SimpleImputer(strategy=\"median\")\n",
    "df[[\"carwidth\"]] = imputer_carwidth.fit_transform(df[[\"carwidth\"]])\n",
    "\n",
    "scaler_carwidth = RobustScaler()\n",
    "df[[\"carwidth\"]] = scaler_carwidth.fit_transform(df[[\"carwidth\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler_stroke = RobustScaler()\n",
    "df[[\"stroke\"]] = scaler_stroke.fit_transform(df[[\"stroke\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `curbweight`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>curbweight</code> normal bir daÄŸÄ±lÄ±ma sahiptir ve aykÄ±rÄ± deÄŸer (outlier) iÃ§ermez. Bu nedenle Standard Scaler ile Ã¶lÃ§eklenebilir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler_curbweight = RobustScaler()\n",
    "df[[\"curbweight\"]] = scaler_curbweight.fit_transform(df[[\"curbweight\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/dilay/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/dilay/Desktop/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_scaling.py::TestScaling::test_carwidth \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 25%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_curbweight \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 50%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_peakrpm \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 75%]\u001b[0m\n",
      "test_scaling.py::TestScaling::test_stroke \u001b[32mPASSED\u001b[0m\u001b[32m                         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.49s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/scaling.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed scaling step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = df\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Kategorik Ã¶zelliklerin kodlanmasÄ± (Encoding the categorical features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: Kategorik deÄŸiÅŸkenlerin encode edilmesi** â“\n",
    "\n",
    "ğŸ‘‡ Encode edilmesi gereken featureâ€™larÄ± inceleyin ve duruma gÃ¶re aÅŸaÄŸÄ±daki teknikleri uygulayÄ±n:\n",
    "\n",
    "- One-hot encoding\n",
    "- Manuel ordinal encoding\n",
    "\n",
    "DataFrame iÃ§inde, orijinal featureâ€™larÄ± encode edilmiÅŸ versiyonlarÄ±yla deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `aspiration` & `enginelocation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>aspiration</code> ve <code>enginelocation</code> ikili (binary) kategorik featureâ€™lardÄ±r.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# aspiration: std / turbo\n",
    "df[\"aspiration\"] = df[\"aspiration\"].map({\"std\": 0, \"turbo\": 1})\n",
    "\n",
    "# enginelocation: front / rear\n",
    "df[\"enginelocation\"] = df[\"enginelocation\"].map({\"front\": 0, \"rear\": 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `enginetype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ <i>Ä°pucu</i> </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>enginetype</code> Ã§ok kategorili (multicategorical) bir featureâ€™dÄ±r ve One-hot encoding uygulanmalÄ±dÄ±r.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"enginetype\"], drop_first=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cylindernumber`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "\n",
    "â„¹ï¸ <code>cylindernumber</code> sÄ±ralÄ± (ordinal) bir featureâ€™dÄ±r ve sayÄ±sal deÄŸerlere manuel olarak encode edilmelidir.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "cylinder_map = {\n",
    "    \"two\": 2,\n",
    "    \"three\": 3,\n",
    "    \"four\": 4,\n",
    "    \"five\": 5,\n",
    "    \"six\": 6,\n",
    "    \"eight\": 8,\n",
    "    \"twelve\": 12\n",
    "}\n",
    "\n",
    "df[\"cylindernumber\"] = df[\"cylindernumber\"].map(cylinder_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ ArtÄ±k `cylindernumber`â€™Ä± 2 ile 12 arasÄ±nda sayÄ±sal bir featureâ€™a dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼ÄŸÃ¼nÃ¼ze gÃ¶re, bunu Ã¶lÃ§eklendirmeniz gerekiyor â“\n",
    "\n",
    "<br/>\n",
    "\n",
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu </summary>\n",
    "\n",
    "`cylindernumber`â€™Ä±n mevcut daÄŸÄ±lÄ±mÄ±na bakÄ±n ve kendinize ÅŸu sorularÄ± sorun:\n",
    "- Ã–lÃ§ekleme, bir featureâ€™Ä±n daÄŸÄ±lÄ±mÄ±nÄ± etkiler mi?\n",
    "- Bu featureâ€™Ä±n daÄŸÄ±lÄ±mÄ±na gÃ¶re en uygun Ã¶lÃ§ekleme yÃ¶ntemi hangisidir?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df[[\"cylindernumber\"]] = scaler.fit_transform(df[[\"cylindernumber\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><i>Ã–lÃ§ekleme ve encoding iÅŸlemlerinden sonra DataFrameâ€™inizin nasÄ±l gÃ¶rÃ¼nmesi gerektiÄŸine dair bir ekran gÃ¶rÃ¼ntÃ¼sÃ¼ aÅŸaÄŸÄ±dadÄ±r</i></summary>\n",
    "    \n",
    "    \n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/car_price_after_scaling_and_encoding.png\">    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‡ Hedef `price`Ä± kodlayÄ±n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ’¡ Ä°pucu \n",
    "    </summary>\n",
    "    <br>\n",
    "    â„¹ï¸ <code>price</code> target deÄŸiÅŸkendir ve LabelEncoder ile encode edilmelidir.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"price\"] = le.fit_transform(df[\"price\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/dilay/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/dilay/Desktop/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_encoding.py::TestEncoding::test_aspiration \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 25%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginelocation \u001b[32mPASSED\u001b[0m\u001b[32m               [ 50%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_enginetype \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 75%]\u001b[0m\n",
      "test_encoding.py::TestEncoding::test_price \u001b[32mPASSED\u001b[0m\u001b[32m                        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.49s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/encoding.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed encoding step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding',\n",
    "                         dataset = df)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Temel Modelleme (Base Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘ Veri kÃ¼mesi Ã¶n iÅŸleme tabi tutuldu ve artÄ±k modele uyarlanmaya hazÄ±r. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Soru: Bir classification modelini ilk kez deÄŸerlendirme** â“\n",
    "\n",
    "Ã–n iÅŸlenmiÅŸ bu dataset Ã¼zerinde bir `LogisticRegression` modeli iÃ§in cross-validation Ã§alÄ±ÅŸtÄ±rÄ±n ve elde edilen skoru `base_model_score` adlÄ± deÄŸiÅŸkende saklayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8326585695006747"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "base_model_score = scores.mean()\n",
    "\n",
    "base_model_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/dilay/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/dilay/Desktop/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_base_model.py::TestBase_model::test_base_model_score \u001b[32mPASSED\u001b[0m\u001b[32m         [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.12s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/base_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed base_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('base_model',\n",
    "                         score = base_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Ã–zellik SeÃ§imi  (Feature Selection (with _Permutation Importance_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘©ğŸ»â€ğŸ« Bir featureâ€™Ä±n targetâ€™Ä± tahmin etmede gerÃ§ekten Ã¶nemli olup olmadÄ±ÄŸÄ±nÄ± tespit etmenin gÃ¼Ã§lÃ¼ bir yolu ÅŸudur:\n",
    "\n",
    "1. Bir model Ã§alÄ±ÅŸtÄ±rÄ±n ve skorunu Ã¶lÃ§Ã¼n  \n",
    "2. Bu featureâ€™Ä± karÄ±ÅŸtÄ±rÄ±n (shuffle edin), modeli tekrar Ã§alÄ±ÅŸtÄ±rÄ±n ve skoru tekrar Ã¶lÃ§Ã¼n  \n",
    "    - EÄŸer performans **belirgin ÅŸekilde dÃ¼ÅŸerse**, bu feature Ã¶nemlidir ve **Ã§Ä±karÄ±lmamalÄ±dÄ±r**\n",
    "    - EÄŸer performans **Ã§ok fazla dÃ¼ÅŸmezse**, bu feature **elenebilir**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ **Sorular** â“\n",
    "\n",
    "1. Modele en az bilgi katkÄ±sÄ± saÄŸlayan featureâ€™larÄ± tespit etmek iÃ§in feature permutation uygulayÄ±n.\n",
    "2. Model performansÄ±nÄ±n belirgin ÅŸekilde dÃ¼ÅŸmeye baÅŸladÄ±ÄŸÄ±nÄ± fark edene kadar zayÄ±f featureâ€™larÄ± datasetâ€™ten Ã§Ä±karÄ±n.\n",
    "3. Elde ettiÄŸiniz yeni gÃ¼Ã§lÃ¼ feature setâ€™i ile yeni bir modeli cross-validation ile deÄŸerlendirin ve skorunu `strong_model_score` adlÄ± deÄŸiÅŸkende saklayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['aspiration',\n",
       "  'enginelocation',\n",
       "  'enginetype_dohc',\n",
       "  'enginetype_dohcv',\n",
       "  'enginetype_l',\n",
       "  'enginetype_rotor',\n",
       "  'enginetype_ohcv',\n",
       "  'stroke',\n",
       "  'peakrpm',\n",
       "  'cylindernumber'],\n",
       " 0.8326585695006747,\n",
       " 0.8693657219973009)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx, test_idx = next(cv.split(X, y))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "perm = permutation_importance(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=20,\n",
    "    random_state=42,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "importances = pd.Series(perm.importances_mean, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "weak_features = importances[importances <= 0].index.tolist()\n",
    "\n",
    "X_strong = X.drop(columns=weak_features) if len(weak_features) > 0 else X.copy()\n",
    "\n",
    "strong_scores = cross_val_score(model, X_strong, y, cv=5)\n",
    "strong_model_score = strong_scores.mean()\n",
    "\n",
    "weak_features, base_model_score, strong_model_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§ª **Kodunu test et**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0 -- /Users/dilay/.pyenv/versions/workintech/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/dilay/Desktop/S16D2-S-Data-car-prices/tests\n",
      "plugins: dash-3.3.0, anyio-4.8.0, typeguard-4.4.2\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_strong_model.py::TestStrong_model::test_strong_model_score \u001b[32mPASSED\u001b[0m\u001b[32m   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.09s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "ğŸ’¯ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/strong_model.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed strong_model step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('strong_model',\n",
    "                         score = strong_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus -  Verilerinizi sÄ±nÄ±flandÄ±rma (Stratifying your data) âš–ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ Veriyi training ve testing olarak bÃ¶lerken, datasetâ€™imizdeki kategorik deÄŸiÅŸkenlerin oranÄ±na dikkat etmemiz gerekir â€” ister target `y`â€™nin sÄ±nÄ±flarÄ± olsun ister `X` iÃ§indeki kategorik bir feature olsun.\n",
    "\n",
    "AÅŸaÄŸÄ±da bir Ã¶rneÄŸe bakalÄ±m ğŸ‘‡\n",
    "\n",
    "â“ Orijinal `X` ve `y` verinizi sklearnâ€™in `train_test_split` fonksiyonunu kullanarak training ve testing olarak ayÄ±rÄ±n; karÅŸÄ±laÅŸtÄ±rÄ±labilir sonuÃ§lar elde etmek iÃ§in `random_state=1` ve `test_size=0.3` kullanÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=1,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Training datasetâ€™inizde ve testing datasetâ€™inizde `price` sÄ±nÄ±fÄ± **1** olan araÃ§larÄ±n oranÄ±nÄ± kontrol edin.\n",
    "\n",
    "> _Ham `df` iÃ§inde bu orana baktÄ±ÄŸÄ±nÄ±zda, yaklaÅŸÄ±k **%50 / %50** olmasÄ± gerekir._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5112781954887218, 0.5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_test.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â˜ï¸ HÃ¢lÃ¢ yaklaÅŸÄ±k olarak **%50 / %50** civarÄ±nda olmalÄ±.\n",
    "\n",
    "***Peki random stateâ€™i deÄŸiÅŸtirirsek ne olur?***\n",
    "\n",
    "â“ `random_state` deÄŸerlerini **1â€™den 10â€™a** kadar dÃ¶ngÃ¼ye alÄ±n ve her seferinde training ve testing datasetâ€™lerindeki `price` sÄ±nÄ±fÄ± **1** olan araÃ§larÄ±n oranÄ±nÄ± hesaplayÄ±n. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 2: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 3: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 4: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 5: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 6: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 7: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 8: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 9: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 10: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios = {}\n",
    "\n",
    "for rs in range(1, 11):\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.3,\n",
    "        random_state=rs,\n",
    "        stratify=y\n",
    "    )\n",
    "    ratios[rs] = {\n",
    "        \"train_ratio\": y_tr.mean(),\n",
    "        \"test_ratio\": y_te.mean()\n",
    "    }\n",
    "\n",
    "ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her seferinde oranlarÄ±n deÄŸiÅŸtiÄŸini, hatta bazen oldukÃ§a ciddi ÅŸekilde deÄŸiÅŸtiÄŸini gÃ¶zlemleyeceksiniz ğŸ˜±! Bu durum model performansÄ±nÄ± etkileyebilir.\n",
    "\n",
    "â“ `train_test_split(random_state=1)` kullanÄ±larak eÄŸitilen bir Logistic Regression modelinin test skorunu,  \n",
    "`random_state=9` kullanÄ±larak eÄŸitilen modelin test skoru ile karÅŸÄ±laÅŸtÄ±rÄ±n â“\n",
    "\n",
    "EÄŸitimi training data Ã¼zerinde yapmayÄ± ve skoru testing data Ã¼zerinde hesaplamayÄ± unutmayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8793103448275862, 0.8448275862068966)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# random_state = 1\n",
    "X_tr1, X_te1, y_tr1, y_te1 = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y\n",
    ")\n",
    "\n",
    "model1 = LogisticRegression(max_iter=2000)\n",
    "model1.fit(X_tr1, y_tr1)\n",
    "score_rs1 = model1.score(X_te1, y_te1)\n",
    "\n",
    "# random_state = 9\n",
    "X_tr9, X_te9, y_tr9, y_te9 = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=9, stratify=y\n",
    ")\n",
    "\n",
    "model9 = LogisticRegression(max_iter=2000)\n",
    "model9.fit(X_tr9, y_tr9)\n",
    "score_rs9 = model9.score(X_te9, y_te9)\n",
    "\n",
    "score_rs1, score_rs9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘€ `random_state=9` ile Ã§ok daha dÃ¼ÅŸÃ¼k bir skor gÃ¶rmelisiniz; Ã§Ã¼nkÃ¼ bu test setindeki sÄ±nÄ±f **1** araÃ§larÄ±n oranÄ± %34.5 iken, training setinde bu oran %57.9â€™a, hatta orijinal datasetâ€™te yaklaÅŸÄ±k %50â€™ye yakÄ±ndÄ±r.\n",
    "\n",
    "Bu durum oldukÃ§a Ã¶nemlidir; Ã§Ã¼nkÃ¼ datasetâ€™te oluÅŸan bu **rastlantÄ±sal dengesizlik**, yalnÄ±zca model performansÄ±nÄ± dÃ¼ÅŸÃ¼rmekle kalmaz, aynÄ± zamanda eÄŸitim veya deÄŸerlendirme sÄ±rasÄ±nda â€œgerÃ§ekliÄŸiâ€ de bozabilir ğŸ§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Peki bu sorunu nasÄ±l Ã§Ã¶zebiliriz? Tren seti ve test seti arasÄ±nda sÄ±nÄ±flarÄ±n daÄŸÄ±lÄ±mÄ±nÄ± nasÄ±l aynÄ± tutabiliriz? ğŸ”§***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Neyse ki sklearnâ€™de, estimator (yani model) bir classifier olduÄŸunda ve target bir sÄ±nÄ±f olduÄŸunda, bu durum `cross_validate` tarafÄ±ndan otomatik olarak ele alÄ±nÄ±r. ğŸ“š [**sklearn.model_selection.cross_validate**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) dokÃ¼mantasyonunda `cv` parametresini inceleyin.\n",
    "\n",
    "Ã‡Ã¶zÃ¼m, aÅŸaÄŸÄ±dakini kullanmaktÄ±r:\n",
    "\n",
    "> ğŸ“š [**Stratification (Katmanlama)**](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hedefin tabakalaÅŸmasÄ± (Stratification of the target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ ***Stratification*** tekniÄŸini `train_test_split` iÃ§inde de kullanabiliriz.\n",
    "\n",
    "â“ Bu kez **1â€™den 10â€™a** kadar olan `random_state` dÃ¶ngÃ¼sÃ¼nÃ¼ tekrar Ã§alÄ±ÅŸtÄ±rÄ±n, ancak bu sefer holdout yÃ¶ntemine ***`stratify=y`*** parametresini de ekleyin. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 2: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 3: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 4: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 5: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 6: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 7: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 8: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 9: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5},\n",
       " 10: {'train_ratio': 0.5112781954887218, 'test_ratio': 0.5}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "stratified_ratios = {}\n",
    "\n",
    "for rs in range(1, 11):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.3,\n",
    "        random_state=rs,\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    stratified_ratios[rs] = {\n",
    "        \"train_ratio\": y_train.mean(),\n",
    "        \"test_ratio\": y_test.mean()\n",
    "    }\n",
    "\n",
    "stratified_ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘€ Random state deÄŸiÅŸse bile, training ve testing verilerindeki sÄ±nÄ±f oranlarÄ±, orijinal `y` iÃ§indeki oranlarla aynÄ± tutulur. Ä°ÅŸte _stratification_ (katmanlama) tam olarak budur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split` fonksiyonunu `stratify` parametresiyle kullandÄ±ÄŸÄ±mÄ±zda, training ve testing verileri arasÄ±nda **bir featureâ€™Ä±n oranlarÄ±nÄ± da koruyabiliriz**. Bu, Ã¶zellikle aÅŸaÄŸÄ±daki durumlarda son derece Ã¶nemlidir:\n",
    "\n",
    "- Churn tahmininde erkek ve kadÄ±n mÃ¼ÅŸteri oranlarÄ±nÄ± korumak ğŸ™‹â€â™‚ï¸ ğŸ™‹\n",
    "- Ev fiyatlarÄ±nÄ± tahmin ederken bÃ¼yÃ¼k ve kÃ¼Ã§Ã¼k evlerin oranlarÄ±nÄ± korumak ğŸ  ğŸ°\n",
    "- Bir sonraki Ã¼rÃ¼nÃ¼ Ã¶nerirken 1â€“5 arasÄ± review score daÄŸÄ±lÄ±mÄ±nÄ± (multiclass!) korumak ğŸ›ï¸\n",
    "- vb.\n",
    "\n",
    "Ã–rneÄŸin, bizim datasetâ€™imizde `aspiration` featureâ€™Ä±nÄ±n training ve testing verilerinde aynÄ± oranda kalmasÄ±nÄ± istiyorsak, ÅŸu ÅŸekilde yazabiliriz:\n",
    "\n",
    "`train_test_split(X, y, test_size=0.3, stratify=X.aspiration)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GÃ¶rdÃ¼ÄŸÃ¼mÃ¼z gibi, **`cross_validate` [target deÄŸiÅŸkeni otomatik olarak stratify edebilir](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#:~:text=For%20int/None%20inputs%2C%20if%20the%20estimator%20is%20a%20classifier%20and%20y%20is%20either%20binary%20or%20multiclass%2C%20StratifiedKFold%20is%20used.)**, ancak **featureâ€™lar iÃ§in bunu yapmaz** ğŸ¤” Bunun iÃ§in biraz ekstra Ã§alÄ±ÅŸmaya ihtiyacÄ±mÄ±z var.\n",
    "\n",
    "Bunun iÃ§in `StratifiedKFold` kullanmamÄ±z gerekiyor ğŸ”¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabakalaÅŸma (Stratification - generalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š [**StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), veriyi `K` parÃ§aya bÃ¶lerken belirli sÃ¼tunlar (feature veya target) Ã¼zerinden stratification yapmamÄ±za olanak tanÄ±r.\n",
    "\n",
    "Bu sayede, ilgilendiÄŸimiz kategorik featureâ€™larÄ±n oranlarÄ±nÄ± koruyarak manuel bir cross-validation yapabiliriz â€” bunu ikili (binary) `aspiration` featureâ€™Ä± ile deneyelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636977058029689"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Veriyi 5 foldâ€™a bÃ¶lecek bir stratified k-fold oluÅŸturma\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = []\n",
    "\n",
    "# .split() metodu bir iterator oluÅŸturur; 'X.aspiration' stratify edeceÄŸimiz featureâ€™dÄ±r\n",
    "for train_indices, test_indices in skf.split(X, X.aspiration):\n",
    "\n",
    "    # 'train_indices' ve 'test_indices', orantÄ±lÄ± bÃ¶lÃ¼nmeler Ã¼reten indeks listeleridir\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "    # modeli baÅŸlatma ve eÄŸitme\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # en sonunda 5 foldâ€™un ortalamasÄ±nÄ± almak iÃ§in skoru listeye ekleme\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "\n",
    "np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“š [**StratifiedKFold**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), veriyi `K` parÃ§aya bÃ¶lerken belirli sÃ¼tunlar (feature veya target) Ã¼zerinden stratification yapmamÄ±za olanak tanÄ±r.\n",
    "\n",
    "Bu sayede, ilgilendiÄŸimiz kategorik featureâ€™larÄ±n oranlarÄ±nÄ± koruyarak manuel bir cross-validation yapabiliriz â€” bunu ikili (binary) `aspiration` featureâ€™Ä± ile deneyelim:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! TÃ¼m veri setini hazÄ±rladÄ±nÄ±z, Ã¶zellik seÃ§imi yaptÄ±nÄ±z ve hatta tabakalaÅŸma hakkÄ±nda bilgi edindiniz ğŸ’ª.\n",
    "\n",
    "ğŸ’¾ Not defterinizi git add/commit/push yapmayÄ± unutmayÄ±n...\n",
    "\n",
    "ğŸš€ ... ve bir sonraki challenge'a geÃ§in!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
